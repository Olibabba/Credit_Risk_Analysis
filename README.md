# Credit_Risk_Analysis

## Overview

In order to build on previous machine learning work, I will now be appling what I've learned to a large real world credit card data set in an aempt to find the best model to predict credit risk. 

Credit risk is an inherently unbalanced classification problem, as good loans easily outnumber risky loans. Therefore, I will will need to employ different techniques to train and evaluate models with unbalanced classes.

I will apply several models to this problem including:
- Oversampling with Random Over Sampler and Smote
- Undersampling with Cluster Centroids
- A cobination over and under sampleing with SMOTEEN
- Ensemble methods with Balanced Random Forest and ADABoost

In adittion I have included two extra notable and popular models:
- XGBoost
- Light GBM


## Results

![Random Over Sampler](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/RandomOverSampler.png)


![SMOTE](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/SMOTE.png)

![Cluster Centroids](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/ClusterCentroids.png)

![SMOTEEN](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/SMOTEEN.png)

![Balanced Random Forest](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/BalancedRandomForest.png)
![BRF Important Features](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/brf_features_list.png)
![BRF Features Plot](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/brf_features_plt.png)

![ADA Boost](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/ADABoost.png)

![XGBoost](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/XGBoost.png)

![LightGBM](https://github.com/Olibabba/Credit_Risk_Analysis/blob/main/resources/LGBM.png)

## Summary